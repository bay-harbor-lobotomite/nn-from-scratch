{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57832092-a908-442c-8f6d-0eae401d69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a44c321-2136-4dcb-af93-9d7813e05be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the very basic value class upon which activations are performed, and can backpropagate through to their parents\n",
    "# we store each value as a member of a DAG with the gradient propagating through its parents\n",
    "class Value():\n",
    "    def __init__(self, data, _op='', _parents=(), ):\n",
    "        self._op = _op\n",
    "        self._backprop = lambda: None\n",
    "        self.grad = 0.0\n",
    "        self.data = data\n",
    "        self._parents = _parents       \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"        \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, _op='+', _parents=(self, other))\n",
    "        def _backprop():\n",
    "            delta = out.grad\n",
    "            self.grad += 1.0*delta\n",
    "            other.grad += 1.0*delta\n",
    "        out._backprop = _backprop\n",
    "        return out\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, _op='*', _parents=(self, other))\n",
    "        def _backprop():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backprop = _backprop\n",
    "        return out\n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    def __neg__(self):\n",
    "        return (-1)*self;      \n",
    "    def __sub__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        return self + (-other)\n",
    "    def __rsub__(self, other):\n",
    "        return (-self) + (other)\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float))\n",
    "        out = Value(self.data**other, _parents=(self, ), _op=f\"^{other}\")\n",
    "        def _backprop():\n",
    "            self.grad += other*(self.data**(other - 1))*out.grad\n",
    "        out._backprop = _backprop\n",
    "        return out\n",
    "    def __truediv__(self, other):\n",
    "        return self*(other**-1)\n",
    "    #unipolar\n",
    "    def sigmoid(self):\n",
    "        x = self.data\n",
    "        sig = 1 / (1 + math.exp(-x))\n",
    "        out = Value(sig, _op='sig', _parents=(self, ))\n",
    "        # the derivative of o = sigmoid is o*(1 - o)\n",
    "        def _backprop():\n",
    "            delta = out.grad * (1 - sig) * sig\n",
    "            self.grad += delta\n",
    "        out._backprop = _backprop        \n",
    "        return out  \n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, _op='tanh', _parents=(self, ))\n",
    "        def _backprop():\n",
    "            delta = out.grad * (1 - t**2)\n",
    "            self.grad += delta\n",
    "        out._backprop = _backprop\n",
    "        return out\n",
    "    def backprop(self):\n",
    "\n",
    "        # toposort\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def topo_sort(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for parent in v._parents:\n",
    "                    topo_sort(parent)\n",
    "                topo.append(v)\n",
    "        topo_sort(self)\n",
    "        self.grad = 1\n",
    "        for node in reversed(topo):\n",
    "            node._backprop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df0af19-69f4-482d-91f2-68fb908cb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "  # builds a set of all nodes and edges in a graph\n",
    "  nodes, edges = set(), set()\n",
    "  def build(v):\n",
    "    if v not in nodes:\n",
    "      nodes.add(v)\n",
    "      for child in v._parents:\n",
    "        edges.add((child, v))\n",
    "        build(child)\n",
    "  build(root)\n",
    "  return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "\n",
    "  nodes, edges = trace(root)\n",
    "  for n in nodes:\n",
    "    uid = str(id(n))\n",
    "    # for any value in the graph, create a rectangular ('record') node for it\n",
    "    dot.node(name = uid, label = \"{ data %.4f | grad %.4f }\" % ( n.data, n.grad), shape='record')\n",
    "    if n._op:\n",
    "      # if this value is a result of some operation, create an op node for it\n",
    "      dot.node(name = uid + n._op, label = n._op)\n",
    "      # and connect this node to it\n",
    "      dot.edge(uid + n._op, uid)\n",
    "\n",
    "  for n1, n2 in edges:\n",
    "    # connect n1 to the op node of n2\n",
    "    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "\n",
    "  return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11436847-6389-402d-82c7-2a16004757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the dimension of input and weights initialized accordingly, single bias\n",
    "class Neuron():\n",
    "    def __init__(self, idim, activation='tanh'):\n",
    "        self.weights = [Value(random.uniform(-1, 1)) for _ in range(idim)]\n",
    "        self.bias = Value(random.uniform(-1, 1))\n",
    "        self.activation = activation\n",
    "    def __repr__(self):\n",
    "        return f\"weights: {self.weights} \\n bias: {self.bias} \\n activation: {self.activation}\"\n",
    "    def parameters(self):\n",
    "        return [self.bias] + self.weights\n",
    "    def forward(self, x):\n",
    "        net = sum((wi*xi for wi, xi in zip(self.weights, x)), self.bias)\n",
    "        activation_func = getattr(net, self.activation, None)\n",
    "        if activation_func is None:\n",
    "            raise ValueError(\"Invalid activation\")\n",
    "        out = activation_func()\n",
    "        return out\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, idim, odim, activation):\n",
    "        self.neurons = [Neuron(idim, activation) for _ in range(odim)]\n",
    "    def __repr__(self):\n",
    "        final = f\"\"\n",
    "        for n in self.neurons:\n",
    "            final += f\"neuron: {repr(n)}\\n\" \n",
    "        return final\n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "    def forward(self, x):\n",
    "        outvec = [n.forward(x) for n in self.neurons]\n",
    "        return outvec[0] if len(outvec) == 1 else outvec\n",
    "\n",
    "#expects an 2D array representing data points, this is a scalar valued library after all\n",
    "class MLP():\n",
    "    def __init__(self, idim, odims, learning_rate, x_in, y_target, activation='tanh', epochs = 20):\n",
    "        dims = [idim] + odims\n",
    "        self.layers = [Layer(dims[i], dims[i+1], activation) for i in range(len(odims))]\n",
    "        self.x_in = x_in\n",
    "        self.y_target = y_target\n",
    "        self.eta = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.preds = None\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    def train(self):\n",
    "        for i in range(self.epochs):\n",
    "            # make prediction\n",
    "            ypred = [self.forward(x) for x in self.x_in]\n",
    "            \n",
    "            #calculate loss - using a simple squared loss here\n",
    "            loss = sum((yp - yt)**2 for yp, yt in zip(ypred, self.y_target))\n",
    "            # minimize the loss using backprop and bump parameters\n",
    "\n",
    "            loss.backprop()\n",
    "            #update\n",
    "            for p in self.parameters():\n",
    "                p.data -= self.eta*p.grad\n",
    "                p.grad = 0.0            \n",
    "            print(f\"Epoch {i}: Loss : {loss.data}\")\n",
    "            self.preds = ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ff88d95-6e34-4674-99ba-84d473d80d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = [[2,0,3,0,-1,0],\n",
    "      [3,0,-1.0,0,5],\n",
    "      [0.5,1.0,1.0],\n",
    "      [1.0,1.0,-1.0]]\n",
    "yt = [1.0, -1.0, -1.0, 1.0]\n",
    "mlp = MLP(idim=3, odims=[4, 4, 1], learning_rate=0.1, x_in=xt, y_target=yt,activation='tanh', epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7554061-8732-46cd-ab7c-0d637851b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss : 4.021491520943238\n",
      "Epoch 1: Loss : 3.815834088673458\n",
      "Epoch 2: Loss : 3.584942988680645\n",
      "Epoch 3: Loss : 3.324742707812087\n",
      "Epoch 4: Loss : 3.107897407706607\n",
      "Epoch 5: Loss : 2.994085530490622\n",
      "Epoch 6: Loss : 2.930887234290701\n",
      "Epoch 7: Loss : 2.8813408712324713\n",
      "Epoch 8: Loss : 2.839489260194895\n",
      "Epoch 9: Loss : 2.802365327902342\n",
      "Epoch 10: Loss : 2.7676869218630658\n",
      "Epoch 11: Loss : 2.7333943322826384\n",
      "Epoch 12: Loss : 2.6972564694442234\n",
      "Epoch 13: Loss : 2.65637559999179\n",
      "Epoch 14: Loss : 2.6063587981812244\n",
      "Epoch 15: Loss : 2.539699318243554\n",
      "Epoch 16: Loss : 2.442535776416516\n",
      "Epoch 17: Loss : 2.2895750882344728\n",
      "Epoch 18: Loss : 2.046234140566972\n",
      "Epoch 19: Loss : 1.7037077084434369\n",
      "Epoch 20: Loss : 1.318468053968852\n",
      "Epoch 21: Loss : 0.9783347231539403\n",
      "Epoch 22: Loss : 0.7328358799819346\n",
      "Epoch 23: Loss : 0.5687562400407039\n",
      "Epoch 24: Loss : 0.4576807828670676\n",
      "Epoch 25: Loss : 0.3794231814416531\n",
      "Epoch 26: Loss : 0.322194836986225\n",
      "Epoch 27: Loss : 0.27912643633901196\n",
      "Epoch 28: Loss : 0.24583463418424803\n",
      "Epoch 29: Loss : 0.21943659792781756\n",
      "Epoch 30: Loss : 0.19806856714794208\n",
      "Epoch 31: Loss : 0.18047497382448258\n",
      "Epoch 32: Loss : 0.16577622122546984\n",
      "Epoch 33: Loss : 0.15333972501113932\n",
      "Epoch 34: Loss : 0.14270042463846086\n",
      "Epoch 35: Loss : 0.13350970132562165\n",
      "Epoch 36: Loss : 0.12550166320030778\n",
      "Epoch 37: Loss : 0.1184703564336091\n",
      "Epoch 38: Loss : 0.11225402652312214\n",
      "Epoch 39: Loss : 0.10672403496750812\n",
      "Epoch 40: Loss : 0.10177691526988145\n",
      "Epoch 41: Loss : 0.09732858685969287\n",
      "Epoch 42: Loss : 0.09331007851545539\n",
      "Epoch 43: Loss : 0.08966432477261084\n",
      "Epoch 44: Loss : 0.08634373634506042\n",
      "Epoch 45: Loss : 0.08330833651586356\n",
      "Epoch 46: Loss : 0.0805243165869107\n",
      "Epoch 47: Loss : 0.07796290522926594\n",
      "Epoch 48: Loss : 0.07559947550771876\n",
      "Epoch 49: Loss : 0.07341283367395039\n",
      "Epoch 50: Loss : 0.07138464827625593\n",
      "Epoch 51: Loss : 0.0694989885355709\n",
      "Epoch 52: Loss : 0.06774194850617285\n",
      "Epoch 53: Loss : 0.06610133910357707\n",
      "Epoch 54: Loss : 0.0645664342124394\n",
      "Epoch 55: Loss : 0.06312776018122532\n",
      "Epoch 56: Loss : 0.06177692034799895\n",
      "Epoch 57: Loss : 0.06050644802214955\n",
      "Epoch 58: Loss : 0.05930968271340914\n",
      "Epoch 59: Loss : 0.05818066545595639\n",
      "Epoch 60: Loss : 0.0571140498977403\n",
      "Epoch 61: Loss : 0.05610502646944093\n",
      "Epoch 62: Loss : 0.055149257455400516\n",
      "Epoch 63: Loss : 0.05424282119162667\n",
      "Epoch 64: Loss : 0.05338216393715442\n",
      "Epoch 65: Loss : 0.05256405822255169\n",
      "Epoch 66: Loss : 0.051785566686844114\n",
      "Epoch 67: Loss : 0.05104401058215284\n",
      "Epoch 68: Loss : 0.050336942262019305\n",
      "Epoch 69: Loss : 0.049662121081086766\n",
      "Epoch 70: Loss : 0.049017492225465684\n",
      "Epoch 71: Loss : 0.04840116806864307\n",
      "Epoch 72: Loss : 0.04781141171027743\n",
      "Epoch 73: Loss : 0.04724662240711092\n",
      "Epoch 74: Loss : 0.04670532264847009\n",
      "Epoch 75: Loss : 0.046186146664996805\n",
      "Epoch 76: Loss : 0.04568783018959676\n",
      "Epoch 77: Loss : 0.04520920131514593\n",
      "Epoch 78: Loss : 0.04474917231507007\n",
      "Epoch 79: Loss : 0.04430673231119271\n",
      "Epoch 80: Loss : 0.04388094068877193\n",
      "Epoch 81: Loss : 0.04347092117187551\n",
      "Epoch 82: Loss : 0.043075856483542736\n",
      "Epoch 83: Loss : 0.042694983524859405\n",
      "Epoch 84: Loss : 0.04232758901538311\n",
      "Epoch 85: Loss : 0.04197300554450728\n",
      "Epoch 86: Loss : 0.04163060798952574\n",
      "Epoch 87: Loss : 0.04129981026149602\n",
      "Epoch 88: Loss : 0.04098006234462545\n",
      "Epoch 89: Loss : 0.040670847598923615\n",
      "Epoch 90: Loss : 0.04037168029936056\n",
      "Epoch 91: Loss : 0.04008210338782363\n",
      "Epoch 92: Loss : 0.03980168641682946\n",
      "Epoch 93: Loss : 0.039530023666284525\n",
      "Epoch 94: Loss : 0.039266732416635114\n",
      "Epoch 95: Loss : 0.03901145136354764\n",
      "Epoch 96: Loss : 0.03876383916084575\n",
      "Epoch 97: Loss : 0.03852357307982844\n",
      "Epoch 98: Loss : 0.03829034777432819\n",
      "Epoch 99: Loss : 0.0380638741419614\n",
      "Epoch 100: Loss : 0.03784387827299149\n",
      "Epoch 101: Loss : 0.03763010047908562\n",
      "Epoch 102: Loss : 0.037422294395009256\n",
      "Epoch 103: Loss : 0.03722022614698432\n",
      "Epoch 104: Loss : 0.037023673582043296\n",
      "Epoch 105: Loss : 0.036832425553252716\n",
      "Epoch 106: Loss : 0.03664628125616521\n",
      "Epoch 107: Loss : 0.03646504961229112\n",
      "Epoch 108: Loss : 0.03628854869577151\n",
      "Epoch 109: Loss : 0.03611660519978169\n",
      "Epoch 110: Loss : 0.03594905393950879\n",
      "Epoch 111: Loss : 0.035785737388828974\n",
      "Epoch 112: Loss : 0.03562650524806421\n",
      "Epoch 113: Loss : 0.03547121404042705\n",
      "Epoch 114: Loss : 0.035319726734970386\n",
      "Epoch 115: Loss : 0.03517191239404459\n",
      "Epoch 116: Loss : 0.03502764584343495\n",
      "Epoch 117: Loss : 0.03488680736350558\n",
      "Epoch 118: Loss : 0.034749282399814424\n",
      "Epoch 119: Loss : 0.034614961291790994\n",
      "Epoch 120: Loss : 0.034483739018183426\n",
      "Epoch 121: Loss : 0.03435551495808438\n",
      "Epoch 122: Loss : 0.034230192666442734\n",
      "Epoch 123: Loss : 0.03410767966305145\n",
      "Epoch 124: Loss : 0.03398788723408523\n",
      "Epoch 125: Loss : 0.03387073024532847\n",
      "Epoch 126: Loss : 0.0337561269663053\n",
      "Epoch 127: Loss : 0.03364399890457915\n",
      "Epoch 128: Loss : 0.033534270649548045\n",
      "Epoch 129: Loss : 0.03342686972510962\n",
      "Epoch 130: Loss : 0.03332172645061823\n",
      "Epoch 131: Loss : 0.03321877380959792\n",
      "Epoch 132: Loss : 0.03311794732571402\n",
      "Epoch 133: Loss : 0.03301918494554304\n",
      "Epoch 134: Loss : 0.03292242692771229\n",
      "Epoch 135: Loss : 0.03282761573801196\n",
      "Epoch 136: Loss : 0.03273469595010989\n",
      "Epoch 137: Loss : 0.03264361415152513\n",
      "Epoch 138: Loss : 0.03255431885454041\n",
      "Epoch 139: Loss : 0.03246676041175549\n",
      "Epoch 140: Loss : 0.032380890936003257\n",
      "Epoch 141: Loss : 0.032296664224369984\n",
      "Epoch 142: Loss : 0.03221403568607786\n",
      "Epoch 143: Loss : 0.03213296227400414\n",
      "Epoch 144: Loss : 0.03205340241962601\n",
      "Epoch 145: Loss : 0.03197531597119492\n",
      "Epoch 146: Loss : 0.031898664134955027\n",
      "Epoch 147: Loss : 0.03182340941923438\n",
      "Epoch 148: Loss : 0.03174951558124711\n",
      "Epoch 149: Loss : 0.03167694757645545\n",
      "Epoch 150: Loss : 0.03160567151035006\n",
      "Epoch 151: Loss : 0.03153565459251637\n",
      "Epoch 152: Loss : 0.031466865092861104\n",
      "Epoch 153: Loss : 0.03139927229988386\n",
      "Epoch 154: Loss : 0.03133284648088236\n",
      "Epoch 155: Loss : 0.031267558843989476\n",
      "Epoch 156: Loss : 0.03120338150194435\n",
      "Epoch 157: Loss : 0.031140287437507096\n",
      "Epoch 158: Loss : 0.03107825047043084\n",
      "Epoch 159: Loss : 0.031017245225910716\n",
      "Epoch 160: Loss : 0.030957247104434163\n",
      "Epoch 161: Loss : 0.03089823225296027\n",
      "Epoch 162: Loss : 0.03084017753736134\n",
      "Epoch 163: Loss : 0.030783060516062992\n",
      "Epoch 164: Loss : 0.03072685941482279\n",
      "Epoch 165: Loss : 0.030671553102590766\n",
      "Epoch 166: Loss : 0.030617121068398742\n",
      "Epoch 167: Loss : 0.030563543399227556\n",
      "Epoch 168: Loss : 0.03051080075880533\n",
      "Epoch 169: Loss : 0.03045887436729086\n",
      "Epoch 170: Loss : 0.03040774598180028\n",
      "Epoch 171: Loss : 0.030357397877736683\n",
      "Epoch 172: Loss : 0.03030781283088408\n",
      "Epoch 173: Loss : 0.030258974100230318\n",
      "Epoch 174: Loss : 0.03021086541148478\n",
      "Epoch 175: Loss : 0.030163470941257948\n",
      "Epoch 176: Loss : 0.030116775301873004\n",
      "Epoch 177: Loss : 0.030070763526779842\n",
      "Epoch 178: Loss : 0.030025421056544585\n",
      "Epoch 179: Loss : 0.029980733725387718\n",
      "Epoch 180: Loss : 0.029936687748246888\n",
      "Epoch 181: Loss : 0.029893269708340463\n",
      "Epoch 182: Loss : 0.02985046654520961\n",
      "Epoch 183: Loss : 0.029808265543217465\n",
      "Epoch 184: Loss : 0.029766654320486037\n",
      "Epoch 185: Loss : 0.029725620818250694\n",
      "Epoch 186: Loss : 0.029685153290614927\n",
      "Epoch 187: Loss : 0.0296452402946876\n",
      "Epoch 188: Loss : 0.02960587068108643\n",
      "Epoch 189: Loss : 0.029567033584791885\n",
      "Epoch 190: Loss : 0.02952871841633716\n",
      "Epoch 191: Loss : 0.029490914853319096\n",
      "Epoch 192: Loss : 0.029453612832217563\n",
      "Epoch 193: Loss : 0.02941680254050969\n",
      "Epoch 194: Loss : 0.02938047440906719\n",
      "Epoch 195: Loss : 0.029344619104824585\n",
      "Epoch 196: Loss : 0.029309227523708188\n",
      "Epoch 197: Loss : 0.029274290783813557\n",
      "Epoch 198: Loss : 0.02923980021882327\n",
      "Epoch 199: Loss : 0.02920574737165375\n",
      "Epoch 200: Loss : 0.029172123988322748\n",
      "Epoch 201: Loss : 0.029138922012028654\n",
      "Epoch 202: Loss : 0.02910613357743279\n",
      "Epoch 203: Loss : 0.029073751005137018\n",
      "Epoch 204: Loss : 0.02904176679634908\n",
      "Epoch 205: Loss : 0.029010173627727835\n",
      "Epoch 206: Loss : 0.028978964346402184\n",
      "Epoch 207: Loss : 0.028948131965155936\n",
      "Epoch 208: Loss : 0.028917669657773287\n",
      "Epoch 209: Loss : 0.02888757075453817\n",
      "Epoch 210: Loss : 0.028857828737881522\n",
      "Epoch 211: Loss : 0.028828437238171405\n",
      "Epoch 212: Loss : 0.028799390029639937\n",
      "Epoch 213: Loss : 0.02877068102644257\n",
      "Epoch 214: Loss : 0.028742304278844225\n",
      "Epoch 215: Loss : 0.028714253969527898\n",
      "Epoch 216: Loss : 0.02868652441002107\n",
      "Epoch 217: Loss : 0.028659110037235765\n",
      "Epoch 218: Loss : 0.028632005410117775\n",
      "Epoch 219: Loss : 0.02860520520640157\n",
      "Epoch 220: Loss : 0.028578704219466452\n",
      "Epoch 221: Loss : 0.028552497355290904\n",
      "Epoch 222: Loss : 0.02852657962950141\n",
      "Epoch 223: Loss : 0.02850094616451191\n",
      "Epoch 224: Loss : 0.028475592186751553\n",
      "Epoch 225: Loss : 0.028450513023976866\n",
      "Epoch 226: Loss : 0.028425704102665768\n",
      "Epoch 227: Loss : 0.028401160945490552\n",
      "Epoch 228: Loss : 0.028376879168866727\n",
      "Epoch 229: Loss : 0.028352854480575677\n",
      "Epoch 230: Loss : 0.028329082677457984\n",
      "Epoch 231: Loss : 0.0283055596431755\n",
      "Epoch 232: Loss : 0.02828228134603951\n",
      "Epoch 233: Loss : 0.028259243836902818\n",
      "Epoch 234: Loss : 0.028236443247113507\n",
      "Epoch 235: Loss : 0.028213875786528612\n",
      "Epoch 236: Loss : 0.028191537741585202\n",
      "Epoch 237: Loss : 0.028169425473427507\n",
      "Epoch 238: Loss : 0.028147535416087534\n",
      "Epoch 239: Loss : 0.028125864074718284\n",
      "Epoch 240: Loss : 0.028104408023877016\n",
      "Epoch 241: Loss : 0.028083163905857314\n",
      "Epoch 242: Loss : 0.028062128429068453\n",
      "Epoch 243: Loss : 0.02804129836646021\n",
      "Epoch 244: Loss : 0.028020670553991857\n",
      "Epoch 245: Loss : 0.02800024188914407\n",
      "Epoch 246: Loss : 0.027980009329471752\n",
      "Epoch 247: Loss : 0.02795996989119732\n",
      "Epoch 248: Loss : 0.02794012064784257\n",
      "Epoch 249: Loss : 0.02792045872889795\n",
      "Epoch 250: Loss : 0.027900981318528396\n",
      "Epoch 251: Loss : 0.027881685654314176\n",
      "Epoch 252: Loss : 0.027862569026025893\n",
      "Epoch 253: Loss : 0.027843628774432663\n",
      "Epoch 254: Loss : 0.02782486229014205\n",
      "Epoch 255: Loss : 0.02780626701247117\n",
      "Epoch 256: Loss : 0.027787840428347886\n",
      "Epoch 257: Loss : 0.027769580071241064\n",
      "Epoch 258: Loss : 0.027751483520119177\n",
      "Epoch 259: Loss : 0.027733548398436197\n",
      "Epoch 260: Loss : 0.027715772373144126\n",
      "Epoch 261: Loss : 0.02769815315373134\n",
      "Epoch 262: Loss : 0.027680688491285816\n",
      "Epoch 263: Loss : 0.027663376177582646\n",
      "Epoch 264: Loss : 0.027646214044195185\n",
      "Epoch 265: Loss : 0.027629199961628843\n",
      "Epoch 266: Loss : 0.027612331838477156\n",
      "Epoch 267: Loss : 0.027595607620599368\n",
      "Epoch 268: Loss : 0.02757902529031881\n",
      "Epoch 269: Loss : 0.02756258286564158\n",
      "Epoch 270: Loss : 0.02754627839949488\n",
      "Epoch 271: Loss : 0.027530109978984467\n",
      "Epoch 272: Loss : 0.027514075724670777\n",
      "Epoch 273: Loss : 0.0274981737898628\n",
      "Epoch 274: Loss : 0.027482402359929655\n",
      "Epoch 275: Loss : 0.027466759651629206\n",
      "Epoch 276: Loss : 0.027451243912453092\n",
      "Epoch 277: Loss : 0.027435853419987725\n",
      "Epoch 278: Loss : 0.02742058648129119\n",
      "Epoch 279: Loss : 0.027405441432285075\n",
      "Epoch 280: Loss : 0.027390416637160957\n",
      "Epoch 281: Loss : 0.027375510487801576\n",
      "Epoch 282: Loss : 0.027360721403215514\n",
      "Epoch 283: Loss : 0.027346047828985802\n",
      "Epoch 284: Loss : 0.027331488236731358\n",
      "Epoch 285: Loss : 0.02731704112358152\n",
      "Epoch 286: Loss : 0.027302705011662855\n",
      "Epoch 287: Loss : 0.027288478447598206\n",
      "Epoch 288: Loss : 0.027274360002017394\n",
      "Epoch 289: Loss : 0.02726034826907956\n",
      "Epoch 290: Loss : 0.027246441866006554\n",
      "Epoch 291: Loss : 0.027232639432627177\n",
      "Epoch 292: Loss : 0.027218939630932134\n",
      "Epoch 293: Loss : 0.027205341144639017\n",
      "Epoch 294: Loss : 0.027191842678767703\n",
      "Epoch 295: Loss : 0.027178442959225037\n",
      "Epoch 296: Loss : 0.027165140732399402\n",
      "Epoch 297: Loss : 0.02715193476476426\n",
      "Epoch 298: Loss : 0.02713882384249093\n",
      "Epoch 299: Loss : 0.02712580677106986\n",
      "Epoch 300: Loss : 0.027112882374940736\n",
      "Epoch 301: Loss : 0.02710004949713069\n",
      "Epoch 302: Loss : 0.02708730699890073\n",
      "Epoch 303: Loss : 0.027074653759399894\n",
      "Epoch 304: Loss : 0.027062088675327403\n",
      "Epoch 305: Loss : 0.02704961066060197\n",
      "Epoch 306: Loss : 0.027037218646038703\n",
      "Epoch 307: Loss : 0.02702491157903287\n",
      "Epoch 308: Loss : 0.027012688423250813\n",
      "Epoch 309: Loss : 0.027000548158327475\n",
      "Epoch 310: Loss : 0.02698848977957067\n",
      "Epoch 311: Loss : 0.02697651229767159\n",
      "Epoch 312: Loss : 0.026964614738421766\n",
      "Epoch 313: Loss : 0.026952796142435995\n",
      "Epoch 314: Loss : 0.026941055564881376\n",
      "Epoch 315: Loss : 0.02692939207521198\n",
      "Epoch 316: Loss : 0.02691780475690933\n",
      "Epoch 317: Loss : 0.026906292707228358\n",
      "Epoch 318: Loss : 0.026894855036948804\n",
      "Epoch 319: Loss : 0.026883490870131685\n",
      "Epoch 320: Loss : 0.026872199343881322\n",
      "Epoch 321: Loss : 0.026860979608111797\n",
      "Epoch 322: Loss : 0.02684983082531884\n",
      "Epoch 323: Loss : 0.026838752170356143\n",
      "Epoch 324: Loss : 0.02682774283021652\n",
      "Epoch 325: Loss : 0.026816802003817426\n",
      "Epoch 326: Loss : 0.02680592890179115\n",
      "Epoch 327: Loss : 0.026795122746279113\n",
      "Epoch 328: Loss : 0.026784382770730558\n",
      "Epoch 329: Loss : 0.02677370821970531\n",
      "Epoch 330: Loss : 0.026763098348680528\n",
      "Epoch 331: Loss : 0.026752552423861438\n",
      "Epoch 332: Loss : 0.026742069721995953\n",
      "Epoch 333: Loss : 0.02673164953019292\n",
      "Epoch 334: Loss : 0.026721291145744175\n",
      "Epoch 335: Loss : 0.02671099387595012\n",
      "Epoch 336: Loss : 0.026700757037948743\n",
      "Epoch 337: Loss : 0.026690579958548222\n",
      "Epoch 338: Loss : 0.02668046197406263\n",
      "Epoch 339: Loss : 0.026670402430151154\n",
      "Epoch 340: Loss : 0.02666040068166031\n",
      "Epoch 341: Loss : 0.026650456092469382\n",
      "Epoch 342: Loss : 0.02664056803533888\n",
      "Epoch 343: Loss : 0.026630735891761962\n",
      "Epoch 344: Loss : 0.026620959051818806\n",
      "Epoch 345: Loss : 0.02661123691403372\n",
      "Epoch 346: Loss : 0.026601568885235235\n",
      "Epoch 347: Loss : 0.026591954380418663\n",
      "Epoch 348: Loss : 0.026582392822611513\n",
      "Epoch 349: Loss : 0.02657288364274145\n",
      "Epoch 350: Loss : 0.0265634262795067\n",
      "Epoch 351: Loss : 0.026554020179249137\n",
      "Epoch 352: Loss : 0.026544664795829575\n",
      "Epoch 353: Loss : 0.026535359590505583\n",
      "Epoch 354: Loss : 0.026526104031811687\n",
      "Epoch 355: Loss : 0.026516897595441524\n",
      "Epoch 356: Loss : 0.02650773976413269\n",
      "Epoch 357: Loss : 0.026498630027553368\n",
      "Epoch 358: Loss : 0.026489567882191284\n",
      "Epoch 359: Loss : 0.026480552831244654\n",
      "Epoch 360: Loss : 0.026471584384515322\n",
      "Epoch 361: Loss : 0.02646266205830365\n",
      "Epoch 362: Loss : 0.026453785375305582\n",
      "Epoch 363: Loss : 0.02644495386451155\n",
      "Epoch 364: Loss : 0.02643616706110711\n",
      "Epoch 365: Loss : 0.026427424506375672\n",
      "Epoch 366: Loss : 0.026418725747602782\n",
      "Epoch 367: Loss : 0.026410070337982303\n",
      "Epoch 368: Loss : 0.026401457836524235\n",
      "Epoch 369: Loss : 0.026392887807964255\n",
      "Epoch 370: Loss : 0.026384359822674903\n",
      "Epoch 371: Loss : 0.02637587345657833\n",
      "Epoch 372: Loss : 0.0263674282910607\n",
      "Epoch 373: Loss : 0.026359023912888094\n",
      "Epoch 374: Loss : 0.026350659914123886\n",
      "Epoch 375: Loss : 0.02634233589204771\n",
      "Epoch 376: Loss : 0.026334051449075763\n",
      "Epoch 377: Loss : 0.026325806192682592\n",
      "Epoch 378: Loss : 0.026317599735324243\n",
      "Epoch 379: Loss : 0.02630943169436288\n",
      "Epoch 380: Loss : 0.026301301691992476\n",
      "Epoch 381: Loss : 0.026293209355166217\n",
      "Epoch 382: Loss : 0.026285154315524712\n",
      "Epoch 383: Loss : 0.026277136209325886\n",
      "Epoch 384: Loss : 0.026269154677375894\n",
      "Epoch 385: Loss : 0.02626120936496115\n",
      "Epoch 386: Loss : 0.026253299921781846\n",
      "Epoch 387: Loss : 0.02624542600188632\n",
      "Epoch 388: Loss : 0.0262375872636067\n",
      "Epoch 389: Loss : 0.026229783369495663\n",
      "Epoch 390: Loss : 0.026222013986264232\n",
      "Epoch 391: Loss : 0.026214278784720765\n",
      "Epoch 392: Loss : 0.026206577439710776\n",
      "Epoch 393: Loss : 0.02619890963005801\n",
      "Epoch 394: Loss : 0.02619127503850635\n",
      "Epoch 395: Loss : 0.02618367335166285\n",
      "Epoch 396: Loss : 0.026176104259941664\n",
      "Epoch 397: Loss : 0.026168567457508903\n",
      "Epoch 398: Loss : 0.026161062642228453\n",
      "Epoch 399: Loss : 0.026153589515608762\n",
      "Epoch 400: Loss : 0.026146147782750376\n",
      "Epoch 401: Loss : 0.026138737152294537\n",
      "Epoch 402: Loss : 0.026131357336372514\n",
      "Epoch 403: Loss : 0.02612400805055577\n",
      "Epoch 404: Loss : 0.026116689013807072\n",
      "Epoch 405: Loss : 0.026109399948432314\n",
      "Epoch 406: Loss : 0.026102140580033167\n",
      "Epoch 407: Loss : 0.026094910637460465\n",
      "Epoch 408: Loss : 0.02608770985276854\n",
      "Epoch 409: Loss : 0.02608053796117001\n",
      "Epoch 410: Loss : 0.026073394700991542\n",
      "Epoch 411: Loss : 0.026066279813630328\n",
      "Epoch 412: Loss : 0.02605919304351111\n",
      "Epoch 413: Loss : 0.026052134138044043\n",
      "Epoch 414: Loss : 0.026045102847583233\n",
      "Epoch 415: Loss : 0.02603809892538588\n",
      "Epoch 416: Loss : 0.026031122127572144\n",
      "Epoch 417: Loss : 0.026024172213085624\n",
      "Epoch 418: Loss : 0.02601724894365448\n",
      "Epoch 419: Loss : 0.026010352083753144\n",
      "Epoch 420: Loss : 0.026003481400564778\n",
      "Epoch 421: Loss : 0.02599663666394418\n",
      "Epoch 422: Loss : 0.02598981764638126\n",
      "Epoch 423: Loss : 0.02598302412296533\n",
      "Epoch 424: Loss : 0.025976255871349642\n",
      "Epoch 425: Loss : 0.025969512671716755\n",
      "Epoch 426: Loss : 0.025962794306744294\n",
      "Epoch 427: Loss : 0.025956100561571292\n",
      "Epoch 428: Loss : 0.02594943122376514\n",
      "Epoch 429: Loss : 0.025942786083288823\n",
      "Epoch 430: Loss : 0.02593616493246896\n",
      "Epoch 431: Loss : 0.025929567565964172\n",
      "Epoch 432: Loss : 0.025922993780733913\n",
      "Epoch 433: Loss : 0.02591644337600795\n",
      "Epoch 434: Loss : 0.02590991615325616\n",
      "Epoch 435: Loss : 0.02590341191615879\n",
      "Epoch 436: Loss : 0.02589693047057737\n",
      "Epoch 437: Loss : 0.02589047162452581\n",
      "Epoch 438: Loss : 0.02588403518814211\n",
      "Epoch 439: Loss : 0.025877620973660514\n",
      "Epoch 440: Loss : 0.025871228795383942\n",
      "Epoch 441: Loss : 0.025864858469657016\n",
      "Epoch 442: Loss : 0.02585850981483934\n",
      "Epoch 443: Loss : 0.02585218265127934\n",
      "Epoch 444: Loss : 0.025845876801288414\n",
      "Epoch 445: Loss : 0.02583959208911539\n",
      "Epoch 446: Loss : 0.02583332834092157\n",
      "Epoch 447: Loss : 0.025827085384755977\n",
      "Epoch 448: Loss : 0.025820863050531093\n",
      "Epoch 449: Loss : 0.025814661169998778\n",
      "Epoch 450: Loss : 0.025808479576726814\n",
      "Epoch 451: Loss : 0.025802318106075653\n",
      "Epoch 452: Loss : 0.02579617659517535\n",
      "Epoch 453: Loss : 0.02579005488290327\n",
      "Epoch 454: Loss : 0.025783952809861604\n",
      "Epoch 455: Loss : 0.02577787021835561\n",
      "Epoch 456: Loss : 0.025771806952372023\n",
      "Epoch 457: Loss : 0.025765762857557824\n",
      "Epoch 458: Loss : 0.02575973778119919\n",
      "Epoch 459: Loss : 0.025753731572201\n",
      "Epoch 460: Loss : 0.025747744081066365\n",
      "Epoch 461: Loss : 0.025741775159876724\n",
      "Epoch 462: Loss : 0.025735824662271926\n",
      "Epoch 463: Loss : 0.02572989244343097\n",
      "Epoch 464: Loss : 0.025723978360052684\n",
      "Epoch 465: Loss : 0.025718082270336833\n",
      "Epoch 466: Loss : 0.025712204033965586\n",
      "Epoch 467: Loss : 0.025706343512085075\n",
      "Epoch 468: Loss : 0.025700500567287274\n",
      "Epoch 469: Loss : 0.02569467506359232\n",
      "Epoch 470: Loss : 0.025688866866430682\n",
      "Epoch 471: Loss : 0.02568307584262607\n",
      "Epoch 472: Loss : 0.025677301860378247\n",
      "Epoch 473: Loss : 0.025671544789246166\n",
      "Epoch 474: Loss : 0.025665804500131402\n",
      "Epoch 475: Loss : 0.02566008086526184\n",
      "Epoch 476: Loss : 0.0256543737581754\n",
      "Epoch 477: Loss : 0.025648683053704307\n",
      "Epoch 478: Loss : 0.025643008627959256\n",
      "Epoch 479: Loss : 0.025637350358314045\n",
      "Epoch 480: Loss : 0.025631708123390346\n",
      "Epoch 481: Loss : 0.025626081803042516\n",
      "Epoch 482: Loss : 0.02562047127834298\n",
      "Epoch 483: Loss : 0.025614876431567492\n",
      "Epoch 484: Loss : 0.025609297146180772\n",
      "Epoch 485: Loss : 0.02560373330682225\n",
      "Epoch 486: Loss : 0.025598184799292104\n",
      "Epoch 487: Loss : 0.025592651510537363\n",
      "Epoch 488: Loss : 0.025587133328638417\n",
      "Epoch 489: Loss : 0.025581630142795405\n",
      "Epoch 490: Loss : 0.02557614184331507\n",
      "Epoch 491: Loss : 0.025570668321597642\n",
      "Epoch 492: Loss : 0.025565209470123945\n",
      "Epoch 493: Loss : 0.025559765182442677\n",
      "Epoch 494: Loss : 0.025554335353157875\n",
      "Epoch 495: Loss : 0.025548919877916507\n",
      "Epoch 496: Loss : 0.02554351865339632\n",
      "Epoch 497: Loss : 0.02553813157729372\n",
      "Epoch 498: Loss : 0.025532758548311944\n",
      "Epoch 499: Loss : 0.025527399466149344\n",
      "Epoch 500: Loss : 0.025522054231487783\n",
      "Epoch 501: Loss : 0.02551672274598128\n",
      "Epoch 502: Loss : 0.025511404912244712\n",
      "Epoch 503: Loss : 0.025506100633842715\n",
      "Epoch 504: Loss : 0.025500809815278788\n",
      "Epoch 505: Loss : 0.025495532361984406\n",
      "Epoch 506: Loss : 0.025490268180308404\n",
      "Epoch 507: Loss : 0.025485017177506404\n",
      "Epoch 508: Loss : 0.02547977926173053\n",
      "Epoch 509: Loss : 0.025474554342019076\n",
      "Epoch 510: Loss : 0.02546934232828639\n",
      "Epoch 511: Loss : 0.025464143131312972\n",
      "Epoch 512: Loss : 0.025458956662735566\n",
      "Epoch 513: Loss : 0.025453782835037464\n",
      "Epoch 514: Loss : 0.025448621561538924\n",
      "Epoch 515: Loss : 0.025443472756387676\n",
      "Epoch 516: Loss : 0.025438336334549626\n",
      "Epoch 517: Loss : 0.025433212211799647\n",
      "Epoch 518: Loss : 0.025428100304712382\n",
      "Epoch 519: Loss : 0.025423000530653383\n",
      "Epoch 520: Loss : 0.025417912807770216\n",
      "Epoch 521: Loss : 0.025412837054983668\n",
      "Epoch 522: Loss : 0.025407773191979136\n",
      "Epoch 523: Loss : 0.025402721139198118\n",
      "Epoch 524: Loss : 0.02539768081782982\n",
      "Epoch 525: Loss : 0.025392652149802786\n",
      "Epoch 526: Loss : 0.02538763505777672\n",
      "Epoch 527: Loss : 0.025382629465134452\n",
      "Epoch 528: Loss : 0.025377635295973863\n",
      "Epoch 529: Loss : 0.025372652475100024\n",
      "Epoch 530: Loss : 0.025367680928017455\n",
      "Epoch 531: Loss : 0.025362720580922357\n",
      "Epoch 532: Loss : 0.025357771360695135\n",
      "Epoch 533: Loss : 0.025352833194892684\n",
      "Epoch 534: Loss : 0.025347906011741275\n",
      "Epoch 535: Loss : 0.025342989740129024\n",
      "Epoch 536: Loss : 0.02533808430959877\n",
      "Epoch 537: Loss : 0.025333189650340933\n",
      "Epoch 538: Loss : 0.025328305693186507\n",
      "Epoch 539: Loss : 0.025323432369600052\n",
      "Epoch 540: Loss : 0.0253185696116729\n",
      "Epoch 541: Loss : 0.0253137173521163\n",
      "Epoch 542: Loss : 0.02530887552425483\n",
      "Epoch 543: Loss : 0.02530404406201968\n",
      "Epoch 544: Loss : 0.02529922289994225\n",
      "Epoch 545: Loss : 0.02529441197314756\n",
      "Epoch 546: Loss : 0.02528961121734803\n",
      "Epoch 547: Loss : 0.0252848205688371\n",
      "Epoch 548: Loss : 0.025280039964483025\n",
      "Epoch 549: Loss : 0.025275269341722806\n",
      "Epoch 550: Loss : 0.02527050863855608\n",
      "Epoch 551: Loss : 0.025265757793539147\n",
      "Epoch 552: Loss : 0.02526101674577908\n",
      "Epoch 553: Loss : 0.02525628543492785\n",
      "Epoch 554: Loss : 0.025251563801176602\n",
      "Epoch 555: Loss : 0.02524685178524993\n",
      "Epoch 556: Loss : 0.025242149328400295\n",
      "Epoch 557: Loss : 0.02523745637240237\n",
      "Epoch 558: Loss : 0.02523277285954768\n",
      "Epoch 559: Loss : 0.025228098732639072\n",
      "Epoch 560: Loss : 0.025223433934985426\n",
      "Epoch 561: Loss : 0.025218778410396325\n",
      "Epoch 562: Loss : 0.0252141321031768\n",
      "Epoch 563: Loss : 0.025209494958122237\n",
      "Epoch 564: Loss : 0.025204866920513193\n",
      "Epoch 565: Loss : 0.025200247936110417\n",
      "Epoch 566: Loss : 0.025195637951149815\n",
      "Epoch 567: Loss : 0.025191036912337542\n",
      "Epoch 568: Loss : 0.0251864447668452\n",
      "Epoch 569: Loss : 0.025181861462304885\n",
      "Epoch 570: Loss : 0.02517728694680459\n",
      "Epoch 571: Loss : 0.025172721168883427\n",
      "Epoch 572: Loss : 0.02516816407752695\n",
      "Epoch 573: Loss : 0.0251636156221627\n",
      "Epoch 574: Loss : 0.02515907575265556\n",
      "Epoch 575: Loss : 0.02515454441930336\n",
      "Epoch 576: Loss : 0.025150021572832346\n",
      "Epoch 577: Loss : 0.025145507164392927\n",
      "Epoch 578: Loss : 0.025141001145555293\n",
      "Epoch 579: Loss : 0.025136503468305118\n",
      "Epoch 580: Loss : 0.02513201408503942\n",
      "Epoch 581: Loss : 0.025127532948562296\n",
      "Epoch 582: Loss : 0.025123060012080922\n",
      "Epoch 583: Loss : 0.025118595229201297\n",
      "Epoch 584: Loss : 0.02511413855392442\n",
      "Epoch 585: Loss : 0.025109689940642155\n",
      "Epoch 586: Loss : 0.025105249344133395\n",
      "Epoch 587: Loss : 0.025100816719560097\n",
      "Epoch 588: Loss : 0.025096392022463453\n",
      "Epoch 589: Loss : 0.02509197520876017\n",
      "Epoch 590: Loss : 0.025087566234738616\n",
      "Epoch 591: Loss : 0.02508316505705512\n",
      "Epoch 592: Loss : 0.025078771632730378\n",
      "Epoch 593: Loss : 0.02507438591914571\n",
      "Epoch 594: Loss : 0.025070007874039603\n",
      "Epoch 595: Loss : 0.02506563745550402\n",
      "Epoch 596: Loss : 0.02506127462198102\n",
      "Epoch 597: Loss : 0.025056919332259245\n",
      "Epoch 598: Loss : 0.025052571545470425\n",
      "Epoch 599: Loss : 0.025048231221086112\n",
      "Epoch 600: Loss : 0.02504389831891426\n",
      "Epoch 601: Loss : 0.02503957279909592\n",
      "Epoch 602: Loss : 0.02503525462210197\n",
      "Epoch 603: Loss : 0.025030943748729856\n",
      "Epoch 604: Loss : 0.025026640140100465\n",
      "Epoch 605: Loss : 0.02502234375765487\n",
      "Epoch 606: Loss : 0.025018054563151242\n",
      "Epoch 607: Loss : 0.025013772518661763\n",
      "Epoch 608: Loss : 0.02500949758656951\n",
      "Epoch 609: Loss : 0.02500522972956554\n",
      "Epoch 610: Loss : 0.025000968910645786\n",
      "Epoch 611: Loss : 0.024996715093108156\n",
      "Epoch 612: Loss : 0.024992468240549594\n",
      "Epoch 613: Loss : 0.02498822831686319\n",
      "Epoch 614: Loss : 0.024983995286235287\n",
      "Epoch 615: Loss : 0.024979769113142695\n",
      "Epoch 616: Loss : 0.024975549762349912\n",
      "Epoch 617: Loss : 0.024971337198906263\n",
      "Epoch 618: Loss : 0.02496713138814324\n",
      "Epoch 619: Loss : 0.024962932295671793\n",
      "Epoch 620: Loss : 0.02495873988737958\n",
      "Epoch 621: Loss : 0.024954554129428458\n",
      "Epoch 622: Loss : 0.02495037498825165\n",
      "Epoch 623: Loss : 0.02494620243055145\n",
      "Epoch 624: Loss : 0.024942036423296333\n",
      "Epoch 625: Loss : 0.024937876933718666\n",
      "Epoch 626: Loss : 0.0249337239293121\n",
      "Epoch 627: Loss : 0.02492957737782911\n",
      "Epoch 628: Loss : 0.024925437247278498\n",
      "Epoch 629: Loss : 0.024921303505923045\n",
      "Epoch 630: Loss : 0.024917176122277084\n",
      "Epoch 631: Loss : 0.024913055065104068\n",
      "Epoch 632: Loss : 0.02490894030341429\n",
      "Epoch 633: Loss : 0.02490483180646256\n",
      "Epoch 634: Loss : 0.024900729543745816\n",
      "Epoch 635: Loss : 0.02489663348500101\n",
      "Epoch 636: Loss : 0.02489254360020269\n",
      "Epoch 637: Loss : 0.02488845985956089\n",
      "Epoch 638: Loss : 0.024884382233518854\n",
      "Epoch 639: Loss : 0.024880310692750974\n",
      "Epoch 640: Loss : 0.024876245208160452\n",
      "Epoch 641: Loss : 0.024872185750877348\n",
      "Epoch 642: Loss : 0.024868132292256345\n",
      "Epoch 643: Loss : 0.024864084803874767\n",
      "Epoch 644: Loss : 0.024860043257530374\n",
      "Epoch 645: Loss : 0.024856007625239505\n",
      "Epoch 646: Loss : 0.024851977879234894\n",
      "Epoch 647: Loss : 0.024847953991963708\n",
      "Epoch 648: Loss : 0.024843935936085675\n",
      "Epoch 649: Loss : 0.024839923684470983\n",
      "Epoch 650: Loss : 0.024835917210198427\n",
      "Epoch 651: Loss : 0.024831916486553432\n",
      "Epoch 652: Loss : 0.024827921487026252\n",
      "Epoch 653: Loss : 0.02482393218530997\n",
      "Epoch 654: Loss : 0.02481994855529874\n",
      "Epoch 655: Loss : 0.02481597057108592\n",
      "Epoch 656: Loss : 0.02481199820696221\n",
      "Epoch 657: Loss : 0.024808031437413912\n",
      "Epoch 658: Loss : 0.024804070237121126\n",
      "Epoch 659: Loss : 0.02480011458095596\n",
      "Epoch 660: Loss : 0.024796164443980837\n",
      "Epoch 661: Loss : 0.02479221980144672\n",
      "Epoch 662: Loss : 0.02478828062879147\n",
      "Epoch 663: Loss : 0.024784346901638016\n",
      "Epoch 664: Loss : 0.024780418595792893\n",
      "Epoch 665: Loss : 0.024776495687244333\n",
      "Epoch 666: Loss : 0.024772578152160902\n",
      "Epoch 667: Loss : 0.024768665966889654\n",
      "Epoch 668: Loss : 0.024764759107954587\n",
      "Epoch 669: Loss : 0.02476085755205515\n",
      "Epoch 670: Loss : 0.0247569612760645\n",
      "Epoch 671: Loss : 0.024753070257028113\n",
      "Epoch 672: Loss : 0.02474918447216213\n",
      "Epoch 673: Loss : 0.024745303898851885\n",
      "Epoch 674: Loss : 0.024741428514650363\n",
      "Epoch 675: Loss : 0.02473755829727671\n",
      "Epoch 676: Loss : 0.024733693224614793\n",
      "Epoch 677: Loss : 0.0247298332747117\n",
      "Epoch 678: Loss : 0.02472597842577629\n",
      "Epoch 679: Loss : 0.024722128656177723\n",
      "Epoch 680: Loss : 0.02471828394444414\n",
      "Epoch 681: Loss : 0.024714444269261192\n",
      "Epoch 682: Loss : 0.02471060960947059\n",
      "Epoch 683: Loss : 0.02470677994406888\n",
      "Epoch 684: Loss : 0.0247029552522059\n",
      "Epoch 685: Loss : 0.024699135513183576\n",
      "Epoch 686: Loss : 0.024695320706454485\n",
      "Epoch 687: Loss : 0.024691510811620597\n",
      "Epoch 688: Loss : 0.024687705808431926\n",
      "Epoch 689: Loss : 0.024683905676785255\n",
      "Epoch 690: Loss : 0.024680110396722833\n",
      "Epoch 691: Loss : 0.0246763199484311\n",
      "Epoch 692: Loss : 0.024672534312239452\n",
      "Epoch 693: Loss : 0.024668753468618985\n",
      "Epoch 694: Loss : 0.024664977398181256\n",
      "Epoch 695: Loss : 0.02466120608167701\n",
      "Epoch 696: Loss : 0.024657439499995108\n",
      "Epoch 697: Loss : 0.024653677634161177\n",
      "Epoch 698: Loss : 0.02464992046533651\n",
      "Epoch 699: Loss : 0.02464616797481687\n",
      "Epoch 700: Loss : 0.024642420144031285\n",
      "Epoch 701: Loss : 0.024638676954541028\n",
      "Epoch 702: Loss : 0.024634938388038277\n",
      "Epoch 703: Loss : 0.024631204426345168\n",
      "Epoch 704: Loss : 0.024627475051412575\n",
      "Epoch 705: Loss : 0.024623750245319032\n",
      "Epoch 706: Loss : 0.02462002999026964\n",
      "Epoch 707: Loss : 0.024616314268594952\n",
      "Epoch 708: Loss : 0.024612603062749948\n",
      "Epoch 709: Loss : 0.024608896355312937\n",
      "Epoch 710: Loss : 0.024605194128984497\n",
      "Epoch 711: Loss : 0.024601496366586456\n",
      "Epoch 712: Loss : 0.02459780305106082\n",
      "Epoch 713: Loss : 0.024594114165468802\n",
      "Epoch 714: Loss : 0.02459042969298975\n",
      "Epoch 715: Loss : 0.02458674961692021\n",
      "Epoch 716: Loss : 0.02458307392067283\n",
      "Epoch 717: Loss : 0.024579402587775488\n",
      "Epoch 718: Loss : 0.024575735601870246\n",
      "Epoch 719: Loss : 0.024572072946712386\n",
      "Epoch 720: Loss : 0.0245684146061695\n",
      "Epoch 721: Loss : 0.0245647605642205\n",
      "Epoch 722: Loss : 0.024561110804954663\n",
      "Epoch 723: Loss : 0.024557465312570734\n",
      "Epoch 724: Loss : 0.024553824071376042\n",
      "Epoch 725: Loss : 0.024550187065785514\n",
      "Epoch 726: Loss : 0.02454655428032078\n",
      "Epoch 727: Loss : 0.024542925699609305\n",
      "Epoch 728: Loss : 0.024539301308383513\n",
      "Epoch 729: Loss : 0.024535681091479897\n",
      "Epoch 730: Loss : 0.024532065033838136\n",
      "Epoch 731: Loss : 0.024528453120500227\n",
      "Epoch 732: Loss : 0.024524845336609653\n",
      "Epoch 733: Loss : 0.024521241667410532\n",
      "Epoch 734: Loss : 0.024517642098246792\n",
      "Epoch 735: Loss : 0.024514046614561306\n",
      "Epoch 736: Loss : 0.02451045520189511\n",
      "Epoch 737: Loss : 0.02450686784588653\n",
      "Epoch 738: Loss : 0.02450328453227047\n",
      "Epoch 739: Loss : 0.02449970524687753\n",
      "Epoch 740: Loss : 0.024496129975633222\n",
      "Epoch 741: Loss : 0.02449255870455726\n",
      "Epoch 742: Loss : 0.024488991419762685\n",
      "Epoch 743: Loss : 0.024485428107455166\n",
      "Epoch 744: Loss : 0.024481868753932202\n",
      "Epoch 745: Loss : 0.02447831334558235\n",
      "Epoch 746: Loss : 0.02447476186888459\n",
      "Epoch 747: Loss : 0.02447121431040742\n",
      "Epoch 748: Loss : 0.02446767065680819\n",
      "Epoch 749: Loss : 0.024464130894832476\n",
      "Epoch 750: Loss : 0.02446059501131315\n",
      "Epoch 751: Loss : 0.02445706299316986\n",
      "Epoch 752: Loss : 0.024453534827408238\n",
      "Epoch 753: Loss : 0.02445001050111919\n",
      "Epoch 754: Loss : 0.02444649000147821\n",
      "Epoch 755: Loss : 0.02444297331574473\n",
      "Epoch 756: Loss : 0.024439460431261377\n",
      "Epoch 757: Loss : 0.024435951335453357\n",
      "Epoch 758: Loss : 0.02443244601582773\n",
      "Epoch 759: Loss : 0.024428944459972783\n",
      "Epoch 760: Loss : 0.024425446655557383\n",
      "Epoch 761: Loss : 0.024421952590330268\n",
      "Epoch 762: Loss : 0.024418462252119473\n",
      "Epoch 763: Loss : 0.02441497562883165\n",
      "Epoch 764: Loss : 0.02441149270845143\n",
      "Epoch 765: Loss : 0.024408013479040827\n",
      "Epoch 766: Loss : 0.024404537928738576\n",
      "Epoch 767: Loss : 0.02440106604575952\n",
      "Epoch 768: Loss : 0.024397597818394106\n",
      "Epoch 769: Loss : 0.024394133235007574\n",
      "Epoch 770: Loss : 0.02439067228403952\n",
      "Epoch 771: Loss : 0.024387214954003283\n",
      "Epoch 772: Loss : 0.02438376123348529\n",
      "Epoch 773: Loss : 0.024380311111144526\n",
      "Epoch 774: Loss : 0.024376864575711945\n",
      "Epoch 775: Loss : 0.024373421615989863\n",
      "Epoch 776: Loss : 0.024369982220851443\n",
      "Epoch 777: Loss : 0.024366546379240097\n",
      "Epoch 778: Loss : 0.024363114080168953\n",
      "Epoch 779: Loss : 0.02435968531272026\n",
      "Epoch 780: Loss : 0.024356260066044872\n",
      "Epoch 781: Loss : 0.024352838329361717\n",
      "Epoch 782: Loss : 0.02434942009195724\n",
      "Epoch 783: Loss : 0.024346005343184863\n",
      "Epoch 784: Loss : 0.024342594072464464\n",
      "Epoch 785: Loss : 0.024339186269281846\n",
      "Epoch 786: Loss : 0.024335781923188228\n",
      "Epoch 787: Loss : 0.024332381023799747\n",
      "Epoch 788: Loss : 0.0243289835607969\n",
      "Epoch 789: Loss : 0.024325589523924097\n",
      "Epoch 790: Loss : 0.024322198902989086\n",
      "Epoch 791: Loss : 0.02431881168786255\n",
      "Epoch 792: Loss : 0.024315427868477527\n",
      "Epoch 793: Loss : 0.02431204743482896\n",
      "Epoch 794: Loss : 0.02430867037697325\n",
      "Epoch 795: Loss : 0.02430529668502769\n",
      "Epoch 796: Loss : 0.024301926349170073\n",
      "Epoch 797: Loss : 0.024298559359638157\n",
      "Epoch 798: Loss : 0.024295195706729285\n",
      "Epoch 799: Loss : 0.024291835380799796\n",
      "Epoch 800: Loss : 0.02428847837226468\n",
      "Epoch 801: Loss : 0.024285124671597037\n",
      "Epoch 802: Loss : 0.02428177426932772\n",
      "Epoch 803: Loss : 0.024278427156044818\n",
      "Epoch 804: Loss : 0.0242750833223932\n",
      "Epoch 805: Loss : 0.024271742759074157\n",
      "Epoch 806: Loss : 0.024268405456844878\n",
      "Epoch 807: Loss : 0.024265071406518072\n",
      "Epoch 808: Loss : 0.02426174059896153\n",
      "Epoch 809: Loss : 0.024258413025097708\n",
      "Epoch 810: Loss : 0.024255088675903237\n",
      "Epoch 811: Loss : 0.02425176754240865\n",
      "Epoch 812: Loss : 0.02424844961569783\n",
      "Epoch 813: Loss : 0.024245134886907656\n",
      "Epoch 814: Loss : 0.024241823347227614\n",
      "Epoch 815: Loss : 0.02423851498789938\n",
      "Epoch 816: Loss : 0.024235209800216387\n",
      "Epoch 817: Loss : 0.024231907775523493\n",
      "Epoch 818: Loss : 0.02422860890521652\n",
      "Epoch 819: Loss : 0.024225313180741944\n",
      "Epoch 820: Loss : 0.024222020593596436\n",
      "Epoch 821: Loss : 0.024218731135326528\n",
      "Epoch 822: Loss : 0.024215444797528192\n",
      "Epoch 823: Loss : 0.0242121615718465\n",
      "Epoch 824: Loss : 0.024208881449975274\n",
      "Epoch 825: Loss : 0.024205604423656633\n",
      "Epoch 826: Loss : 0.02420233048468072\n",
      "Epoch 827: Loss : 0.02419905962488524\n",
      "Epoch 828: Loss : 0.024195791836155216\n",
      "Epoch 829: Loss : 0.02419252711042256\n",
      "Epoch 830: Loss : 0.024189265439665687\n",
      "Epoch 831: Loss : 0.02418600681590927\n",
      "Epoch 832: Loss : 0.02418275123122381\n",
      "Epoch 833: Loss : 0.0241794986777253\n",
      "Epoch 834: Loss : 0.0241762491475749\n",
      "Epoch 835: Loss : 0.02417300263297862\n",
      "Epoch 836: Loss : 0.02416975912618692\n",
      "Epoch 837: Loss : 0.02416651861949444\n",
      "Epoch 838: Loss : 0.02416328110523965\n",
      "Epoch 839: Loss : 0.024160046575804478\n",
      "Epoch 840: Loss : 0.024156815023614064\n",
      "Epoch 841: Loss : 0.024153586441136396\n",
      "Epoch 842: Loss : 0.024150360820881976\n",
      "Epoch 843: Loss : 0.024147138155403525\n",
      "Epoch 844: Loss : 0.024143918437295638\n",
      "Epoch 845: Loss : 0.024140701659194564\n",
      "Epoch 846: Loss : 0.024137487813777773\n",
      "Epoch 847: Loss : 0.02413427689376373\n",
      "Epoch 848: Loss : 0.024131068891911543\n",
      "Epoch 849: Loss : 0.02412786380102074\n",
      "Epoch 850: Loss : 0.024124661613930877\n",
      "Epoch 851: Loss : 0.0241214623235213\n",
      "Epoch 852: Loss : 0.024118265922710817\n",
      "Epoch 853: Loss : 0.02411507240445744\n",
      "Epoch 854: Loss : 0.024111881761758085\n",
      "Epoch 855: Loss : 0.02410869398764827\n",
      "Epoch 856: Loss : 0.024105509075201852\n",
      "Epoch 857: Loss : 0.024102327017530716\n",
      "Epoch 858: Loss : 0.024099147807784535\n",
      "Epoch 859: Loss : 0.02409597143915047\n",
      "Epoch 860: Loss : 0.024092797904852872\n",
      "Epoch 861: Loss : 0.024089627198153076\n",
      "Epoch 862: Loss : 0.024086459312349078\n",
      "Epoch 863: Loss : 0.02408329424077526\n",
      "Epoch 864: Loss : 0.024080131976802147\n",
      "Epoch 865: Loss : 0.02407697251383617\n",
      "Epoch 866: Loss : 0.024073815845319334\n",
      "Epoch 867: Loss : 0.024070661964729043\n",
      "Epoch 868: Loss : 0.024067510865577752\n",
      "Epoch 869: Loss : 0.024064362541412792\n",
      "Epoch 870: Loss : 0.024061216985816078\n",
      "Epoch 871: Loss : 0.02405807419240385\n",
      "Epoch 872: Loss : 0.02405493415482645\n",
      "Epoch 873: Loss : 0.024051796866768074\n",
      "Epoch 874: Loss : 0.02404866232194649\n",
      "Epoch 875: Loss : 0.024045530514112835\n",
      "Epoch 876: Loss : 0.024042401437051376\n",
      "Epoch 877: Loss : 0.024039275084579224\n",
      "Epoch 878: Loss : 0.02403615145054617\n",
      "Epoch 879: Loss : 0.02403303052883437\n",
      "Epoch 880: Loss : 0.024029912313358173\n",
      "Epoch 881: Loss : 0.024026796798063865\n",
      "Epoch 882: Loss : 0.024023683976929444\n",
      "Epoch 883: Loss : 0.02402057384396438\n",
      "Epoch 884: Loss : 0.02401746639320942\n",
      "Epoch 885: Loss : 0.024014361618736307\n",
      "Epoch 886: Loss : 0.024011259514647665\n",
      "Epoch 887: Loss : 0.024008160075076633\n",
      "Epoch 888: Loss : 0.02400506329418679\n",
      "Epoch 889: Loss : 0.024001969166171797\n",
      "Epoch 890: Loss : 0.023998877685255333\n",
      "Epoch 891: Loss : 0.023995788845690775\n",
      "Epoch 892: Loss : 0.02399270264176099\n",
      "Epoch 893: Loss : 0.02398961906777818\n",
      "Epoch 894: Loss : 0.02398653811808367\n",
      "Epoch 895: Loss : 0.023983459787047624\n",
      "Epoch 896: Loss : 0.023980384069068942\n",
      "Epoch 897: Loss : 0.023977310958574964\n",
      "Epoch 898: Loss : 0.023974240450021368\n",
      "Epoch 899: Loss : 0.02397117253789185\n",
      "Epoch 900: Loss : 0.02396810721669808\n",
      "Epoch 901: Loss : 0.023965044480979317\n",
      "Epoch 902: Loss : 0.02396198432530239\n",
      "Epoch 903: Loss : 0.023958926744261373\n",
      "Epoch 904: Loss : 0.023955871732477495\n",
      "Epoch 905: Loss : 0.023952819284598883\n",
      "Epoch 906: Loss : 0.023949769395300382\n",
      "Epoch 907: Loss : 0.023946722059283398\n",
      "Epoch 908: Loss : 0.023943677271275682\n",
      "Epoch 909: Loss : 0.02394063502603114\n",
      "Epoch 910: Loss : 0.02393759531832971\n",
      "Epoch 911: Loss : 0.023934558142977062\n",
      "Epoch 912: Loss : 0.023931523494804586\n",
      "Epoch 913: Loss : 0.02392849136866906\n",
      "Epoch 914: Loss : 0.023925461759452527\n",
      "Epoch 915: Loss : 0.02392243466206215\n",
      "Epoch 916: Loss : 0.02391941007142999\n",
      "Epoch 917: Loss : 0.023916387982512877\n",
      "Epoch 918: Loss : 0.023913368390292202\n",
      "Epoch 919: Loss : 0.02391035128977374\n",
      "Epoch 920: Loss : 0.023907336675987552\n",
      "Epoch 921: Loss : 0.02390432454398773\n",
      "Epoch 922: Loss : 0.02390131488885225\n",
      "Epoch 923: Loss : 0.02389830770568286\n",
      "Epoch 924: Loss : 0.02389530298960487\n",
      "Epoch 925: Loss : 0.023892300735766984\n",
      "Epoch 926: Loss : 0.023889300939341156\n",
      "Epoch 927: Loss : 0.023886303595522466\n",
      "Epoch 928: Loss : 0.023883308699528843\n",
      "Epoch 929: Loss : 0.023880316246601065\n",
      "Epoch 930: Loss : 0.0238773262320025\n",
      "Epoch 931: Loss : 0.02387433865101896\n",
      "Epoch 932: Loss : 0.02387135349895857\n",
      "Epoch 933: Loss : 0.02386837077115162\n",
      "Epoch 934: Loss : 0.023865390462950373\n",
      "Epoch 935: Loss : 0.02386241256972898\n",
      "Epoch 936: Loss : 0.023859437086883286\n",
      "Epoch 937: Loss : 0.023856464009830637\n",
      "Epoch 938: Loss : 0.023853493334009875\n",
      "Epoch 939: Loss : 0.02385052505488104\n",
      "Epoch 940: Loss : 0.023847559167925282\n",
      "Epoch 941: Loss : 0.023844595668644792\n",
      "Epoch 942: Loss : 0.023841634552562527\n",
      "Epoch 943: Loss : 0.023838675815222154\n",
      "Epoch 944: Loss : 0.023835719452187865\n",
      "Epoch 945: Loss : 0.02383276545904433\n",
      "Epoch 946: Loss : 0.02382981383139641\n",
      "Epoch 947: Loss : 0.023826864564869158\n",
      "Epoch 948: Loss : 0.023823917655107597\n",
      "Epoch 949: Loss : 0.023820973097776622\n",
      "Epoch 950: Loss : 0.02381803088856088\n",
      "Epoch 951: Loss : 0.023815091023164564\n",
      "Epoch 952: Loss : 0.023812153497311386\n",
      "Epoch 953: Loss : 0.02380921830674436\n",
      "Epoch 954: Loss : 0.02380628544722571\n",
      "Epoch 955: Loss : 0.023803354914536765\n",
      "Epoch 956: Loss : 0.023800426704477757\n",
      "Epoch 957: Loss : 0.023797500812867772\n",
      "Epoch 958: Loss : 0.02379457723554458\n",
      "Epoch 959: Loss : 0.02379165596836451\n",
      "Epoch 960: Loss : 0.023788737007202375\n",
      "Epoch 961: Loss : 0.02378582034795127\n",
      "Epoch 962: Loss : 0.023782905986522516\n",
      "Epoch 963: Loss : 0.023779993918845513\n",
      "Epoch 964: Loss : 0.02377708414086761\n",
      "Epoch 965: Loss : 0.023774176648554017\n",
      "Epoch 966: Loss : 0.023771271437887615\n",
      "Epoch 967: Loss : 0.023768368504868985\n",
      "Epoch 968: Loss : 0.023765467845516086\n",
      "Epoch 969: Loss : 0.02376256945586434\n",
      "Epoch 970: Loss : 0.02375967333196637\n",
      "Epoch 971: Loss : 0.02375677946989197\n",
      "Epoch 972: Loss : 0.02375388786572797\n",
      "Epoch 973: Loss : 0.023750998515578083\n",
      "Epoch 974: Loss : 0.023748111415562864\n",
      "Epoch 975: Loss : 0.02374522656181955\n",
      "Epoch 976: Loss : 0.023742343950501968\n",
      "Epoch 977: Loss : 0.02373946357778042\n",
      "Epoch 978: Loss : 0.023736585439841584\n",
      "Epoch 979: Loss : 0.02373370953288839\n",
      "Epoch 980: Loss : 0.023730835853139925\n",
      "Epoch 981: Loss : 0.023727964396831346\n",
      "Epoch 982: Loss : 0.02372509516021372\n",
      "Epoch 983: Loss : 0.023722228139553977\n",
      "Epoch 984: Loss : 0.023719363331134793\n",
      "Epoch 985: Loss : 0.023716500731254468\n",
      "Epoch 986: Loss : 0.023713640336226808\n",
      "Epoch 987: Loss : 0.023710782142381093\n",
      "Epoch 988: Loss : 0.023707926146061944\n",
      "Epoch 989: Loss : 0.023705072343629147\n",
      "Epoch 990: Loss : 0.023702220731457703\n",
      "Epoch 991: Loss : 0.023699371305937585\n",
      "Epoch 992: Loss : 0.023696524063473754\n",
      "Epoch 993: Loss : 0.02369367900048595\n",
      "Epoch 994: Loss : 0.02369083611340874\n",
      "Epoch 995: Loss : 0.02368799539869125\n",
      "Epoch 996: Loss : 0.02368515685279724\n",
      "Epoch 997: Loss : 0.023682320472204903\n",
      "Epoch 998: Loss : 0.023679486253406795\n",
      "Epoch 999: Loss : 0.02367665419290975\n"
     ]
    }
   ],
   "source": [
    "mlp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214445f9-c289-44bf-a835-9555c8c5bd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9519890821879483),\n",
       " Value(data=-0.9736512099673912),\n",
       " Value(data=-0.9472615145436858),\n",
       " Value(data=0.9529255850336709)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8b6c1-f48c-4546-9b8f-d2a1f8c847ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
